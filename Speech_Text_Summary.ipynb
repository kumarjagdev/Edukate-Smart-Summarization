{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Speech to Text & Summarization"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Setup\nTo prepare your environment, you need to install some packages.\n\nInstall the necessary packages\n\nYou need the latest versions of these packages:"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting ibm-watson>=4.5.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/da/10f8774b319acdda29885931c01fae862622519bff492957c73b0ba84743/ibm-watson-4.5.0.tar.gz (370kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 378kB 8.6MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson>=4.5.0) (2.21.0)\nRequirement already satisfied, skipping upgrade: python_dateutil>=2.5.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-watson>=4.5.0) (2.7.5)\nCollecting websocket-client==0.48.0 (from ibm-watson>=4.5.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/a1/72ef9aa26cfe1a75cee09fc1957e4723add9de098c15719416a1ee89386b/websocket_client-0.48.0-py2.py3-none-any.whl (198kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 204kB 24.0MB/s eta 0:00:01\n\u001b[?25hCollecting ibm_cloud_sdk_core==1.5.1 (from ibm-watson>=4.5.0)\n  Downloading https://files.pythonhosted.org/packages/b7/f6/10d5271c807d73d236e6ae07b68035fed78b28b5ab836704d34097af3986/ibm-cloud-sdk-core-1.5.1.tar.gz\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->ibm-watson>=4.5.0) (3.0.4)\nRequirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->ibm-watson>=4.5.0) (1.24.1)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->ibm-watson>=4.5.0) (2.8)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->ibm-watson>=4.5.0) (2020.6.20)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python_dateutil>=2.5.3->ibm-watson>=4.5.0) (1.12.0)\nCollecting PyJWT>=1.7.1 (from ibm_cloud_sdk_core==1.5.1->ibm-watson>=4.5.0)\n  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\nBuilding wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n  Building wheel for ibm-watson (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/71/9a/0a/9b3ca8eca69bc5362eb04709a750b30055a9d27818fd0c9494\n  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/6a/42/50/f96888116b329578304f9dda4693cef6f3e76e18272d22cb6c\nSuccessfully built ibm-watson ibm-cloud-sdk-core\nInstalling collected packages: websocket-client, PyJWT, ibm-cloud-sdk-core, ibm-watson\nSuccessfully installed PyJWT-1.7.1 ibm-cloud-sdk-core-1.5.1 ibm-watson-4.5.0 websocket-client-0.48.0\n"
                }
            ],
            "source": "!pip install --upgrade \"ibm-watson>=4.5.0\""
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting watson-developer-cloud==1.5\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/fc/1a76bd8d60a6912db4c3382d288b10e033548abaa6a55a1292dedfe63e35/watson-developer-cloud-1.5.0.tar.gz (215kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 225kB 7.6MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-developer-cloud==1.5) (2.21.0)\nRequirement already satisfied: python_dateutil>=2.5.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-developer-cloud==1.5) (2.7.5)\nCollecting autobahn>=0.10.9 (from watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/2a/8874a5a32a56ecc9c859f1daa281ffd87ec6047e49ab30804a0b3b2707d8/autobahn-20.7.1-py2.py3-none-any.whl (1.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.5MB 15.5MB/s eta 0:00:01\n\u001b[?25hCollecting Twisted>=13.2.0 (from watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/04/1a664c9e5ec0224a1c1a154ddecaa4dc7b8967521bba225efcc41a03d5f3/Twisted-20.3.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.1MB 43.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pyOpenSSL>=16.2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-developer-cloud==1.5) (19.0.0)\nCollecting service-identity>=17.0.0 (from watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud==1.5) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud==1.5) (2020.6.20)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud==1.5) (2.8)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson-developer-cloud==1.5) (1.24.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python_dateutil>=2.5.3->watson-developer-cloud==1.5) (1.12.0)\nCollecting cryptography>=2.7 (from autobahn>=0.10.9->watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/91/84a29d6a27fd6dfc21f475704c4d2053d58ed7a4033c2b0ce1b4ca4d03d9/cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.7MB 42.8MB/s eta 0:00:01\n\u001b[?25hCollecting txaio>=20.3.1 (from autobahn>=0.10.9->watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/4f/82/0cd8d81d57e55a598cd4cef10c6e971dbcaf437e4f138dc1624cf7c1388e/txaio-20.4.1-py2.py3-none-any.whl\nCollecting incremental>=16.10.1 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\nCollecting constantly>=15.1 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\nCollecting attrs>=19.2.0 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\nCollecting hyperlink>=17.1.1 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/7f/91/e916ca10a2de1cb7101a9b24da546fb90ee14629e23160086cf3361c4fb8/hyperlink-19.0.0-py2.py3-none-any.whl\nCollecting PyHamcrest!=1.10.0,>=1.9.0 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/16/e54cc65891f01cb62893540f44ffd3e8dab0a22443e1b438f1a9f5574bee/PyHamcrest-2.0.2-py3-none-any.whl (52kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 25.5MB/s eta 0:00:01\n\u001b[?25hCollecting Automat>=0.3.0 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\nCollecting zope.interface>=4.4.2 (from Twisted>=13.2.0->watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 235kB 42.4MB/s eta 0:00:01\n\u001b[?25hCollecting pyasn1-modules (from service-identity>=17.0.0->watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163kB 43.0MB/s eta 0:00:01\n\u001b[?25hCollecting pyasn1 (from service-identity>=17.0.0->watson-developer-cloud==1.5)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 81kB 28.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cryptography>=2.7->autobahn>=0.10.9->watson-developer-cloud==1.5) (1.11.5)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from zope.interface>=4.4.2->Twisted>=13.2.0->watson-developer-cloud==1.5) (40.8.0)\nRequirement already satisfied: pycparser in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.7->autobahn>=0.10.9->watson-developer-cloud==1.5) (2.19)\nBuilding wheels for collected packages: watson-developer-cloud\n  Building wheel for watson-developer-cloud (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/81/cd/de/4e0916f623c2d125502e493394fd333ed693960264d4b7e524\nSuccessfully built watson-developer-cloud\nInstalling collected packages: cryptography, txaio, autobahn, incremental, constantly, attrs, hyperlink, PyHamcrest, Automat, zope.interface, Twisted, pyasn1, pyasn1-modules, service-identity, watson-developer-cloud\n  Found existing installation: cryptography 2.5\n    Uninstalling cryptography-2.5:\n      Successfully uninstalled cryptography-2.5\n  Found existing installation: attrs 18.2.0\n    Uninstalling attrs-18.2.0:\n      Successfully uninstalled attrs-18.2.0\nSuccessfully installed Automat-20.2.0 PyHamcrest-2.0.2 Twisted-20.3.0 attrs-19.3.0 autobahn-20.7.1 constantly-15.1.0 cryptography-3.0 hyperlink-19.0.0 incremental-17.5.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 service-identity-18.1.0 txaio-20.4.1 watson-developer-cloud-1.5.0 zope.interface-5.1.0\n"
                }
            ],
            "source": "!pip install watson-developer-cloud==1.5"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting pyldavis\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.6MB 7.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (0.32.3)\nRequirement already satisfied: numpy>=1.9.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (1.15.4)\nRequirement already satisfied: scipy>=0.18.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (1.2.0)\nRequirement already satisfied: pandas>=0.17.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (0.24.1)\nCollecting joblib>=0.8.4 (from pyldavis)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl (300kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 307kB 41.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: jinja2>=2.7.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (2.10)\nRequirement already satisfied: numexpr in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (2.6.9)\nRequirement already satisfied: pytest in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (4.2.1)\nRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pyldavis) (0.17.1)\nCollecting funcy (from pyldavis)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 552kB 36.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.17.0->pyldavis) (2.7.5)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas>=0.17.0->pyldavis) (2018.9)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jinja2>=2.7.2->pyldavis) (1.1.0)\nRequirement already satisfied: py>=1.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (1.7.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (1.12.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (40.8.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (19.3.0)\nRequirement already satisfied: atomicwrites>=1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (1.3.0)\nRequirement already satisfied: pluggy>=0.7 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (0.8.1)\nRequirement already satisfied: more-itertools>=4.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pytest->pyldavis) (5.0.0)\nBuilding wheels for collected packages: pyldavis, funcy\n  Building wheel for pyldavis (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n  Building wheel for funcy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\nSuccessfully built pyldavis funcy\nInstalling collected packages: joblib, funcy, pyldavis\nSuccessfully installed funcy-1.14 joblib-0.16.0 pyldavis-2.1.2\n"
                }
            ],
            "source": "!pip install pyldavis"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting wordcloud\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/e7/f4ed7fac1993615b4ba92f473a77e27a3d210c5d23a000c2c98846963f9a/wordcloud-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (364kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 368kB 7.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/envs/Python36/lib/python3.6/site-packages (from wordcloud) (3.0.2)\nRequirement already satisfied: pillow in /opt/conda/envs/Python36/lib/python3.6/site-packages (from wordcloud) (5.4.1)\nRequirement already satisfied: numpy>=1.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from wordcloud) (1.15.4)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->wordcloud) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->wordcloud) (1.0.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.3.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.7.5)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.12.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (40.8.0)\nInstalling collected packages: wordcloud\nSuccessfully installed wordcloud-1.7.0\n"
                }
            ],
            "source": "!pip install wordcloud"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting gensim\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24.2MB 7.8MB/s eta 0:00:01\n\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/8e/464b06f5efd26f2dc16ce7bd1662c2f31cadf9104fdbcbf5994674cc3a51/smart_open-2.1.0.tar.gz (116kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 122kB 44.6MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.12.0)\nRequirement already satisfied: numpy>=1.11.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.15.4)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from gensim) (1.2.0)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\nRequirement already satisfied: boto in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.9.82)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: botocore<1.13.0,>=1.12.82 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.82)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.3)\nRequirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.1.13)\nRequirement already satisfied: docutils>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.8.1->gensim) (0.14)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.8.1->gensim) (2.7.5)\nBuilding wheels for collected packages: smart-open\n  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/25/6c/db/7dcb26f19fb260c5629af85ed1c8ef9641143444fc7ec1fa08\nSuccessfully built smart-open\nInstalling collected packages: smart-open, gensim\nSuccessfully installed gensim-3.8.3 smart-open-2.1.0\n"
                }
            ],
            "source": "!pip install gensim"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import various packages for Speech to Text"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "import json\nimport os\nimport ibm_boto3\nfrom os.path import join, dirname\nfrom ibm_watson import SpeechToTextV1\nfrom ibm_watson.websocket import RecognizeCallback, AudioSource\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom botocore.client import Config, ClientError"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import various packages for Text Summarization"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/abc.zip.\n[nltk_data]    | Downloading package alpino to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/alpino.zip.\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n[nltk_data]    | Downloading package brown to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/brown.zip.\n[nltk_data]    | Downloading package brown_tei to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n[nltk_data]    | Downloading package cess_cat to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n[nltk_data]    | Downloading package cess_esp to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n[nltk_data]    | Downloading package chat80 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/chat80.zip.\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/city_database.zip.\n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/cmudict.zip.\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n[nltk_data]    | Downloading package comtrans to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package conll2000 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/conll2000.zip.\n[nltk_data]    | Downloading package conll2002 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/conll2002.zip.\n[nltk_data]    | Downloading package conll2007 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package crubadan to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/crubadan.zip.\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n[nltk_data]    | Downloading package dolch to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/dolch.zip.\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n[nltk_data]    | Downloading package floresta to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/floresta.zip.\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/genesis.zip.\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n[nltk_data]    | Downloading package ieer to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/ieer.zip.\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/inaugural.zip.\n[nltk_data]    | Downloading package indian to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/indian.zip.\n[nltk_data]    | Downloading package jeita to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package kimmo to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/kimmo.zip.\n[nltk_data]    | Downloading package knbc to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n[nltk_data]    | Downloading package mac_morpho to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n[nltk_data]    | Downloading package machado to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package masc_tagged to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping models/moses_sample.zip.\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n[nltk_data]    | Downloading package names to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/names.zip.\n[nltk_data]    | Downloading package nombank.1.0 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package nps_chat to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n[nltk_data]    | Downloading package omw to /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/omw.zip.\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n[nltk_data]    | Downloading package paradigms to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/paradigms.zip.\n[nltk_data]    | Downloading package pil to /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/pil.zip.\n[nltk_data]    | Downloading package pl196x to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/pl196x.zip.\n[nltk_data]    | Downloading package ppattach to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/ppattach.zip.\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n[nltk_data]    | Downloading package propbank to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package ptb to /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/ptb.zip.\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n[nltk_data]    | Downloading package pros_cons to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n[nltk_data]    | Downloading package qc to /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/qc.zip.\n[nltk_data]    | Downloading package reuters to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package rte to /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/rte.zip.\n[nltk_data]    | Downloading package semcor to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package senseval to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/senseval.zip.\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n[nltk_data]    | Downloading package smultron to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/smultron.zip.\n[nltk_data]    | Downloading package state_union to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/state_union.zip.\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/stopwords.zip.\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n[nltk_data]    | Downloading package swadesh to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/swadesh.zip.\n[nltk_data]    | Downloading package switchboard to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/switchboard.zip.\n[nltk_data]    | Downloading package timit to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/timit.zip.\n[nltk_data]    | Downloading package toolbox to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/toolbox.zip.\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/treebank.zip.\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n[nltk_data]    | Downloading package udhr to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/udhr.zip.\n[nltk_data]    | Downloading package udhr2 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/udhr2.zip.\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package verbnet to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/verbnet.zip.\n[nltk_data]    | Downloading package verbnet3 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n[nltk_data]    | Downloading package webtext to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/webtext.zip.\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet.zip.\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n[nltk_data]    | Downloading package words to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/words.zip.\n[nltk_data]    | Downloading package ycoe to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/ycoe.zip.\n[nltk_data]    | Downloading package rslp to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping stemmers/rslp.zip.\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n[nltk_data]    | Downloading package punkt to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n[nltk_data]    | Downloading package tagsets to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping help/tagsets.zip.\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package mte_teip5 to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping\n[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping misc/perluniprops.zip.\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    | Downloading package porter_test to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n[nltk_data]    | Downloading package wmt15_eval to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n[nltk_data]    | Downloading package mwa_ppdb to\n[nltk_data]    |     /home/dsxuser/nltk_data...\n[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n"
                },
                {
                    "data": {
                        "text/plain": "True"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from gensim.summarization.summarizer import summarize\nfrom gensim.summarization import keywords\nimport watson_developer_cloud\nfrom botocore.client import Config\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport string\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nimport pyLDAvis\nimport pyLDAvis.gensim  \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport urllib\nfrom bs4 import BeautifulSoup\nimport requests\nimport nltk\nnltk.download('all')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Insert authenticator details"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "authenticator = IAMAuthenticator('enter authentication key')\nspeech_to_text = SpeechToTextV1(\n    authenticator=authenticator)\nspeech_to_text.set_service_url('enter url')"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Insert audio file credetials"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Function to download the audio file to notebook for processing"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "def download_file_cos(credentials,local_file_name,key):  \n    cos_audio = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials_2['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials_2['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials_2['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials_2['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials_2['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Download the audio file using above function"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "cos_audio = ibm_boto3.client('s3',\n                    ibm_api_key_id=credentials_2['IBM_API_KEY_ID'],\n                    ibm_service_instance_id=credentials_2['IAM_SERVICE_ID'],\n                    ibm_auth_endpoint=credentials_2['IBM_AUTH_ENDPOINT'],\n                    config=Config(signature_version='oauth'),\n                    endpoint_url=credentials_2['ENDPOINT'])\ncos_audio.download_file(Bucket=credentials_2['BUCKET'],Key='datafabric.flac',Filename='datafabric.flac')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Convert speech audio file to text"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "with open('datafabric.flac','rb') as audio_file: \n      \n        dic = json.loads( \n                json.dumps( \n                    speech_to_text.recognize( \n                        audio=audio_file, \n                        content_type='audio/flac',    \n                        model='en-US_BroadbandModel', \n                        smart_formatting = True,\n                        continuous = True\n                    ).get_result(), indent=2)) \n  \n# Stores the transcribed text \ntext_str = \"\" \n  \nwhile bool(dic.get('results')): \n    text_str = dic.get('results').pop().get('alternatives').pop().get('transcript').strip()+\". \"+text_str[:]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Define summary and other functions"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "'''Get the summary of the text'''\n\ndef get_summary(text, pct):\n    summary = summarize(text,ratio=pct,split=True)\n    return summary\n\n'''Get the keywords of the text'''\n\ndef get_keywords(text):\n    res = keywords(text, ratio=0.1, words=None, split=False, scores=False, pos_filter=('NN', 'JJ'), lemmatize=False, deacc=False)\n    res = res.split('\\n')\n    return res\n\n'''Tokenize the sentence into words & remove punctuation'''\n\ndef sent_to_words(sentences):\n    for sentence in sentences:\n        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n        \ndef split_sentences(text):\n    \"\"\" Split text into sentences.\n    \"\"\"\n    sentence_delimiters = re.compile(u'[\\\\[\\\\]\\n.!?]')\n    sentences = sentence_delimiters.split(text)\n    return sentences\n\ndef split_into_tokens(text):\n    \"\"\" Split text into tokens.\n    \"\"\"\n    tokens = nltk.word_tokenize(text)\n    return tokens\n    \ndef POS_tagging(text):\n    \"\"\" Generate Part of speech tagging of the text.\n    \"\"\"\n    POSofText = nltk.tag.pos_tag(text)\n    return POSofText\n\ndef extract_title_text(url):\n    page = urllib.request.urlopen(url).read().decode('utf8')\n    soup = BeautifulSoup(page,'lxml')\n    text = ' '.join(map(lambda p: p.text, soup.find_all('p')))\n    return soup.title.text, text"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Write text summary to file"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "summarized_text_list = get_summary(text_str, 0.4)\nsummarized_text = str(summarized_text_list).strip('[]')\nfileobject1 = open(\"data_fabric_summary.txt\",\"w+\")\nfileobject1.write(summarized_text)\nfileobject1.close()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Upload summary file to Cloud Object Storage"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "File Uploaded\n"
                }
            ],
            "source": "    try:\n        res=cos_audio.upload_file(Filename='data_fabric_summary.txt', Bucket=credentials_2['BUCKET'],Key='data_fabric_summary.txt')\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Uploaded')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}